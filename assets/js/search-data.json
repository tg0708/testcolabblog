{
  
    
        "post0": {
            "title": "Selenium",
            "content": "Settings . Warnings . import warnings warnings.filterwarnings(&#39;ignore&#39;) . Autoinstaller . from selenium import webdriver import chromedriver_autoinstaller from selenium.webdriver.common.by import By from selenium.webdriver.chrome.service import Service from webdriver_manager.chrome import ChromeDriverManager import os # Check chrome version chrome_ver = chromedriver_autoinstaller.get_chrome_version().split(&#39;.&#39;)[0] driver_path = f&#39;./{chrome_ver}/chromedriver.exe&#39; # check &#39;./103/chromedriver.exe&#39; if os.path.exists(driver_path): print(f&quot;chrom driver is insatlled : {driver_path}&quot;) else: print(f&quot;install the chrome driver(ver : {chrome_ver})&quot;) # install chromedriver_autoinstaller.install(True) driver = webdriver.Chrome(service=Service(driver_path)) . Options . from selenium import webdriver from selenium.webdriver.chrome.options import Options import warnings import chromedriver_autoinstaller warnings.filterwarnings(&#39;ignore&#39;) options = Options() options.add_argument(&#39;headless&#39;) # headless 모드 options.add_argument(&#39;window-size=1920*1080&#39;) options.add_argument(&#39;--start-maximized&#39;) # 최대화 options.add_argument(&#39;--start-fullscreen&#39;) # 풀스크린 코드 options.add_argument(&#39;--mute-audio&#39;) #브라우저에 음소거 옵션을 적용합니다. options.add_argument(&#39;incognito&#39;) #시크릿 모드의 브라우저가 실행됩니다. options.add_argument(&#39;disable-gpu&#39;) options.add_argument(&#39;User-Agent:Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36&#39;) options.add_argument(&#39;lang=ko-KR&#39;) # 자동화 문구 제거 options.add_experimental_option(&quot;useAutomationExtension&quot;, False) options.add_experimental_option(&quot;excludeSwitches&quot;, [&#39;enable-automation&#39;]) # 디버거 모드 - 안됨 options.add_experimental_option(&quot;debuggerAddress&quot;, &quot;127.0.0.1:9222&quot;) driver_path = &#39;./103/chromedriver.exe&#39; driver = webdriver.Chrome(executable_path= driver_path, options= options) . Execute . from selenium import webdriver from selenium.webdriver.common.keys import Keys from selenium.webdriver.common.by import By from selenium.webdriver.chrome.service import Service from webdriver_manager.chrome import ChromeDriverManager import time # 드라이버 생성 # chromedriver 설치된 경로를 정확히 기재해야 함 chromedriver = r&#39;C: Users tgkang Documents 크롤링2 103 chromedriver.exe&#39; driver = webdriver.Chrome(service=Service(chromedriver)) . Driver . # Selenium은 웹테스트를 위한 프레임워크로 다음과 같은 방식으로 웹테스트를 자동으로 진행함 (참고) print (driver.title) assert &quot;Teddy&quot; in driver.title . Size . # 웹페이지 전체 사이즈 driver.maximize_window() # 웹페이지 전체 사이즈 driver.minimize_window() # 웹페이지 사이즈 조절 driver.set_window_size(1000,1000) # 풀스크린 driver.fullscreen_window() . Handle . # 현재 핸들중인 창 목록 조회 driver.window_handles driver.window_handles[0] # 첫번째 창 driver.window_handles[1] # 두번째 창 driver.window_handles[-1] # 가장 최근에 열린창 . Switch . # switch driver.switch_to.window(driver.window_handles[1]) # iframe으로 이동 driver.switch_to.frame(&#39;iframe name&#39;) # 상위 iframe으로 이동 driver.switch_to.parent_frame() # 초기 frame으로 이동 driver.switch_to.default_content() . Screenshot . # 해당 엘리멘트 스크린샷 후 저장 element.screenshot(&quot;gd.png&quot;) # 특정 태그가 차지하는 만큼 스크린 샷 # body로 지정시 전체 스크린 샷 element = driver.find_elements(By.TAG_NAME, &quot;body&quot;) element.screenshot(&quot;test.png&quot;) . URL . # 현재 url 가져오기 driver.current_url . Clear . # input 텍스트 초기화 element.clear() . Javascript . # user agent 가져오기 driver.execute_script(&#39;return navigator.userAgent&#39;) driver.execute_script(&quot;window.scrollTo(0,Y)&quot;) # Y까지 스크롤 내리기 driver.execute_script(&quot;window.scrollTo(0, document.body.scrollHeight)&quot;) # 끝까지 스크롤 . Send_keys . from selenium.webdriver.common.keys import Keys # 사용가능한 키 조회 dir(Keys) # 키 이벤트 전송 elem.send_keys(&quot;error@error.com&quot;) # 엔터 입력 elem.send_keys(Keys.RETURN) . Element . ID &amp; Css . elem = driver.find_element(By.ID,&quot;navbarMediumish&quot;) elems = driver.find_elements(By.CSS_SELECTOR, &quot;div.card-body &gt; h4&quot;) . Attribute . # 특정 attribute elem = driver.find_elements(By.TAG_NAME, &quot;meta&quot;) for item in elem: data = item.get_attribute(&#39;content&#39;) print(data) . Image . # 이미지 URL 추출 elems = driver.find_elements(By.CSS_SELECTOR, &quot;div.wrapthumbnail img&quot;) sources = list() for elem in elems: sources.append(elem.get_attribute(&#39;src&#39;)) . # 이미지 다운 받기 from urllib.request import urlretrieve image_path = r&quot;C: Users tgkang Documents 크롤링2 103 &quot; for index, source in enumerate(sources): urlretrieve(source, image_path + &quot;image&quot; + str(index) + &quot;.&quot; + source.split(&quot;.&quot;)[-1]) . Xpath . # h1 태그 중 첫번째 태그 가져오기 title = driver.find_element(By.XPATH, &quot;//h1&quot;) # href 속성 모두 선택 datas = driver.find_elements(By.XPATH, &#39;//*[@href]&#39;) # ID = begin 인 속성 모두 찾기 datas = driver.find_elements(By.XPATH, &#39;//*[@id=&quot;begin&quot;]&#39;) # class 의 값이 skill-name 인 div 태그들 중에, HTML 코드 위에서 세번째 해당하는 div 태그 선택 datas = driver.find_elements(By.XPATH, &quot;//div[@class=&#39;skill-name&#39;]&quot;) # class값이 best-list 이고 그 아래 ul li a 태그 datas = driver.find_elements(By.XPATH, &quot;//div[@class=&#39;best-list&#39;]/ul/li/a&quot;) . # 첫 번째 데이터 선택 item = driver.find_element(By.XPATH, &quot;(//tr)[position()=1]&quot;) # 3 번째 보다 작은 번째 선택 item = driver.find_element(By.XPATH, &quot;(//tr)[position()&lt;3]&quot;) # 마지막 데이터 선택 item = driver.find_element(By.XPATH, &quot;(//tr)[last()]&quot;) # 속성을 하나 이상 가진 p 태그 item = driver.find_element_by_xpath(&quot;//p[@*]&quot;) # 다중 선택 elem = driver.find_element_by_xpath(&quot;//*[contains(@class, &#39;course&#39;) and contains(@class, &#39;paid&#39;)]&quot;) . Etc . Title tag 예외사항 . # css selector로 title을 선택해서 text를 뽑으면 나오지 않음 elem = driver.find_element(By.CSS_SELECTOR, &quot;title&quot;) print (&#39;text:&#39;, elem.text) # 가져오지 않음(# text는 보통 body안의 내용을 뽑을 때만) print (&#39;get_attribute:&#39;, elem.get_attribute(&#39;text&#39;)) # 가져와짐 print (&#39;driver.title:&#39;, driver.title) # elem = driver.find_element_by_css_selector(&#39;h1&#39;) elem = driver.find_element(By.CSS_SELECTOR, &quot;h1&quot;) print (&#39;text:&#39;, elem.text) # 됨 print (&#39;get_attribute:&#39;, elem.get_attribute(&#39;text&#39;)) # 될 것 처럼 보이지만 안된다. .",
            "url": "https://tg0708.github.io/testcolabblog/selenium/2022/07/06/Selenium.html",
            "relUrl": "/selenium/2022/07/06/Selenium.html",
            "date": " • Jul 6, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Code",
            "content": "Warnings . import warnings warnings.filterwarnings(&#39;ignore&#39;) . Bs4 . 패턴 . 기본 패턴 . # find import requests from bs4 import BeautifulSoup res = requests.get(&quot;크롤링 할 주소&quot;) soup = BeautifulSoup(res.content, &quot;html.parser&quot;) mydata = soup.find(&#39;title&#39;) print(mydata.text) . # select import requests from bs4 import BeautifulSoup res = requests.get(&#39;https://davelee-fun.github.io/blog/crawl_test_css.html&#39;) soup = BeautifulSoup(res.content, &#39;html.parser&#39;) items = soup.select(&#39;li&#39;) for item in items: print (item.get_text()) . 응답 페이지 확인 . import requests from bs4 import BeautifulSoup res = requests.get(&#39;https://davelee-fun.github.io/xxx&#39;) if res.status_code != 200: print (&#39;페이지 없음&#39;) else: soup = BeautifulSoup(res.content, &#39;html.parser&#39;) data = soup.select(&#39;h4.card-text&#39;) for item in data: print (item.get_text()) . 여러 페이지 . import requests from bs4 import BeautifulSoup for page_num in range(10): if page_num == 0: res = requests.get(&#39;https://davelee-fun.github.io/&#39;) else: res = requests.get(&#39;https://davelee-fun.github.io/page&#39; + str(page_num + 1)) soup = BeautifulSoup(res.content, &#39;html.parser&#39;) data = soup.select(&#39;h4.card-text&#39;) for item in data: print (item.get_text().strip()) . 엑셀 저장 . ! pip install openpyxl . Requirement already satisfied: openpyxl in c: users tgkang anaconda3 lib site-packages (3.0.9) Requirement already satisfied: et-xmlfile in c: users tgkang anaconda3 lib site-packages (from openpyxl) (1.1.0) . import openpyxl def write_excel_template(filename, sheetname, listdata): excel_file = openpyxl.Workbook() excel_sheet = excel_file.active excel_sheet.column_dimensions[&#39;A&#39;].width = 100 excel_sheet.column_dimensions[&#39;B&#39;].width = 20 if sheetname != &#39;&#39;: excel_sheet.title = sheetname for item in listdata: excel_sheet.append(item) excel_file.save(filename) excel_file.close() . import requests from bs4 import BeautifulSoup product_lists = list() for page_num in range(10): if page_num == 0: res = requests.get(&#39;https://davelee-fun.github.io/&#39;) else: res = requests.get(&#39;https://davelee-fun.github.io/page&#39; + str(page_num + 1)) soup = BeautifulSoup(res.content, &#39;html.parser&#39;) data = soup.select(&#39;div.card&#39;) for item in data: product_name = item.select_one(&#39;div.card-body h4.card-text&#39;) product_date = item.select_one(&#39;div.wrapfooter span.post-date&#39;) product_info = [product_name.get_text().strip(), product_date.get_text()] # 리스트 product_lists.append(product_info) write_excel_template(&#39;tmp.xlsx&#39;, &#39;상품정보&#39;, product_lists) . find . data = soup.find(&#39;p&#39;, class_=&#39;cssstyle&#39;) # 태그, 클래스 data = soup.find(&#39;p&#39;, &#39;cssstyle&#39;) # 태그, 클래스 data = soup.find(&#39;p&#39;, attrs = {&#39;align&#39;: &#39;center&#39;}) # 태그, 속성 data = soup.find(id=&#39;body&#39;) # 아이디 data = soup.find(&#39;h3&#39;,&#39;tit_view&#39;) data = soup.find(&#39;div&#39;, &#39;layer_util layer_summary&#39;) . select . items = soup.select(&#39;.course&#39;) # 클래스 items = soup.select(&#39;#start&#39;) # 아이디 items = soup.select(&#39;td[valign=&quot;top&quot;]&#39;) # 태그, 특정 속성 items = soup.findAll(&quot;td&quot;, {&quot;valign&quot; : re.compile(r&quot;.*&quot;)}) # 정규 표현식 items = soup.select(&#39;li.course.paid&#39;) # 태그, 클래스1, 클래스2 items = soup.select(&#39;html body h1&#39;) # 하위 태그 items = soup.select(&#39;ul &gt; li&#39;) # 직계 하위 태그 items = soup.select(&#39;ul#hobby_course_list li.course&#39;) # 태그, 아이디, 하위 태그, 클래스 item = soup.select_one(&#39;ul#dev_course_list &gt; li.course.paid&#39;) . 활용예제 . # G마켓 베스트 상품 url = &quot;http://corners.gmarket.co.kr/Bestsellers?viewType=G&amp;groupCode=G06&quot; res = requests.get(url) if res.status_code != 200: print(&quot;응답 없음&quot;) else : soup = BeautifulSoup(res.content, &#39;html.parser&#39;) bestlist = soup.select(&#39;.best-list li&#39;) for idx, item in enumerate(bestlist): item_list = item.select_one(&#39;div .itemname&#39;).text.strip() price_list = item.select_one(&#39;div .s-price span&#39;).text.strip() print(idx+1,item_list,&quot; - &quot;, price_list) . Selenium . 기본 패턴 . from selenium import webdriver from selenium.webdriver.common.keys import Keys from selenium.webdriver.common.by import By from selenium.webdriver.chrome.service import Service from webdriver_manager.chrome import ChromeDriverManager import time # 드라이버 생성 # chromedriver 설치된 경로를 정확히 기재해야 함 chromedriver = r&#39;C: Users tgkang Documents 크롤링2 103 chromedriver.exe&#39; driver = webdriver.Chrome(service=Service(chromedriver)) . Autoinstaller . from selenium import webdriver import chromedriver_autoinstaller import os from selenium.webdriver.common.by import By from selenium.webdriver.chrome.service import Service from webdriver_manager.chrome import ChromeDriverManager # Check if chrome driver is installed or not chrome_ver = chromedriver_autoinstaller.get_chrome_version().split(&#39;.&#39;)[0] driver_path = f&#39;./{chrome_ver}/chromedriver.exe&#39; if os.path.exists(driver_path): print(f&quot;chrom driver is insatlled : {driver_path}&quot;) else: print(f&quot;install the chrome driver(ver : {chrome_ver})&quot;) chromedriver_autoinstaller.install(True) driver = webdriver.Chrome(service=Service(driver_path)) . Options . from selenium import webdriver from selenium.webdriver.chrome.options import Options import warnings import chromedriver_autoinstaller warnings.filterwarnings(&#39;ignore&#39;) options = Options() options.add_argument(&#39;headless&#39;) # headless 모드 options.add_argument(&#39;window-size=1920*1080&#39;) options.add_argument(&#39;--start-maximized&#39;) # 최대화 options.add_argument(&#39;--start-fullscreen&#39;) # 풀스크린 코드 options.add_argument(&#39;--mute-audio&#39;) #브라우저에 음소거 옵션을 적용합니다. options.add_argument(&#39;incognito&#39;) #시크릿 모드의 브라우저가 실행됩니다. options.add_argument(&#39;disable-gpu&#39;) options.add_argument(&#39;User-Agent:Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36&#39;) options.add_argument(&#39;lang=ko-KR&#39;) # 자동화 문구 제거 options.add_experimental_option(&quot;useAutomationExtension&quot;, False) options.add_experimental_option(&quot;excludeSwitches&quot;, [&#39;enable-automation&#39;]) # 디버거 모드 - 안됨 options.add_experimental_option(&quot;debuggerAddress&quot;, &quot;127.0.0.1:9222&quot;) driver_path = &#39;./103/chromedriver.exe&#39; driver = webdriver.Chrome(executable_path= driver_path, options= options) . Driver . Assert . # Selenium은 웹테스트를 위한 프레임워크로 다음과 같은 방식으로 웹테스트를 자동으로 진행함 (참고) print (driver.title) assert &quot;Teddy&quot; in driver.title . Size . # 웹페이지 전체 사이즈 driver.maximize_window() # 웹페이지 전체 사이즈 driver.minimize_window() # 웹페이지 사이즈 조절 driver.set_window_size(1000,1000) # 풀스크린 driver.fullscreen_window() . Handle . # 현재 핸들중인 창 목록 조회 driver.window_handles driver.window_handles[0] # 첫번째 창 driver.window_handles[1] # 두번째 창 driver.window_handles[-1] # 가장 최근에 열린창 . Switch . # switch driver.switch_to.window(driver.window_handles[1]) # iframe으로 이동 driver.switch_to.frame(&#39;iframe name&#39;) # 상위 iframe으로 이동 driver.switch_to.parent_frame() # 초기 frame으로 이동 driver.switch_to.default_content() . Screenshot . # 해당 엘리멘트 스크린샷 후 저장 element.screenshot(&quot;gd.png&quot;) # 특정 태그가 차지하는 만큼 스크린 샷 # body로 지정시 전체 스크린 샷 element = driver.find_elements(By.TAG_NAME, &quot;body&quot;) element.screenshot(&quot;test.png&quot;) . URL . # 현재 url 가져오기 driver.current_url . Title . # 웹페이지 타이틀 가져오기 driver.title . Clear text . # input 텍스트 초기화 element.clear() . Javascript . # user agent 가져오기 driver.execute_script(&#39;return navigator.userAgent&#39;) driver.execute_script(&quot;window.scrollTo(0,Y)&quot;) # Y까지 스크롤 내리기 driver.execute_script(&quot;window.scrollTo(0, document.body.scrollHeight)&quot;) # 끝까지 스크롤 . Find_element . ID, CSS_SELECTOR . elem = driver.find_element(By.ID,&quot;navbarMediumish&quot;) elems = driver.find_elements(By.CSS_SELECTOR, &quot;div.card-body &gt; h4&quot;) . Get_attribute . # 특정 attribute elem = driver.find_elements(By.TAG_NAME, &quot;meta&quot;) for item in elem: data = item.get_attribute(&#39;content&#39;) print(data) . Image . # 이미지 URL 추출 elems = driver.find_elements(By.CSS_SELECTOR, &quot;div.wrapthumbnail img&quot;) sources = list() for elem in elems: sources.append(elem.get_attribute(&#39;src&#39;)) . # 이미지 다운 받기 from urllib.request import urlretrieve image_path = r&quot;C: Users tgkang Documents 크롤링2 103 &quot; for index, source in enumerate(sources): urlretrieve(source, image_path + &quot;image&quot; + str(index) + &quot;.&quot; + source.split(&quot;.&quot;)[-1]) . Xpath . / : 절대경로를 나타냄 (예: /html/body/div/div) | // : 문서내에서 검색 (예: //h1 -&gt; h1 태그를 가진 데이터를 선택) | //*[@href] : href 속성이 있는 모든 태그 선택 | //a[@href=’http://google.com’] : a 태그의 href 속성에 http://google.com 속성값을 가진 모든 태그 선택 | (//a)[3] : 문서의 세 번째 링크 선택 | (//table)[last()] : 문서의 마지막 테이블 선택 | (//a)[position() &lt; 3] : 문서의 처음 두 링크 선택 | //div[@*] 속성이 하나라도 있는 div 태그 선택 | . # h1 태그 중 첫번째 태그 가져오기 title = driver.find_element(By.XPATH, &quot;//h1&quot;) # href 속성 모두 선택 datas = driver.find_elements(By.XPATH, &#39;//*[@href]&#39;) # ID = begin 인 속성 모두 찾기 datas = driver.find_elements(By.XPATH, &#39;//*[@id=&quot;begin&quot;]&#39;) # class 의 값이 skill-name 인 div 태그들 중에, HTML 코드 위에서 세번째 해당하는 div 태그 선택 datas = driver.find_elements(By.XPATH, &quot;//div[@class=&#39;skill-name&#39;]&quot;) # class값이 best-list 이고 그 아래 ul li a 태그 datas = driver.find_elements(By.XPATH, &quot;//div[@class=&#39;best-list&#39;]/ul/li/a&quot;) # 첫 번째 데이터 선택 item = driver.find_element(By.XPATH, &quot;(//tr)[position()=1]&quot;) # 3 번째 보다 작은 번째 선택 item = driver.find_element(By.XPATH, &quot;(//tr)[position()&lt;3]&quot;) # 마지막 데이터 선택 item = driver.find_element(By.XPATH, &quot;(//tr)[last()]&quot;) # 속성을 하나 이상 가진 p 태그 item = driver.find_element_by_xpath(&quot;//p[@*]&quot;) # 다중 선택 elem = driver.find_element_by_xpath(&quot;//*[contains(@class, &#39;course&#39;) and contains(@class, &#39;paid&#39;)]&quot;) . Title tag 예외 . # css selector로 title을 선택해서 text를 뽑으면 나오지 않음 elem = driver.find_element(By.CSS_SELECTOR, &quot;title&quot;) print (&#39;text:&#39;, elem.text) # 가져오지 않음(# text는 보통 body안의 내용을 뽑을 때만) print (&#39;get_attribute:&#39;, elem.get_attribute(&#39;text&#39;)) # 가져와짐 print (&#39;driver.title:&#39;, driver.title) # elem = driver.find_element_by_css_selector(&#39;h1&#39;) elem = driver.find_element(By.CSS_SELECTOR, &quot;h1&quot;) print (&#39;text:&#39;, elem.text) # 됨 print (&#39;get_attribute:&#39;, elem.get_attribute(&#39;text&#39;)) # 될 것 처럼 보이지만 안된다. . Send_key . from selenium.webdriver.common.keys import Keys # 사용가능한 키 조회 dir(Keys) # 키 이벤트 전송 elem.send_keys(&quot;error@error.com&quot;) # 엔터 입력 elem.send_keys(Keys.RETURN) . Scrapy . 설치 . # 윈도우/맥 공통 ! pip install scrapy . # 윈도우에서 정상 설치 안될 시 ! pip install --upgrade setuptools ! pip install pypiwin32 ! pip install twisted[tls] . 프로젝트 생성 . # 프로젝트 생성 scrapy startproject ecommerce # 크롤러 작성 scrapy genspider &lt;크롤러이름&gt; &lt;크롤링주소&gt; scrapy genspider gmarket &quot;www.gmarket.co.kr&quot; # 크롤러 실행 scrapy crawl gmarket . Scrapy shell . # Scrapy shell 접속 scrapy shell &quot;http://corners.gmarket.co.kr/Bestsellers&quot; exit # 종료 # response요청한 페이지 보기 view(response) # response url 확인 response.url . element . # css selector response.css(&#39;head &gt; title&#39;).get() response.css(&#39;head &gt; title&#39;).getall() response.css(&#39;head &gt; title::text&#39;).get() response.css(&#39;div.best-list li &gt; a::text&#39;).getall() response.css(&#39;div.best-list li &gt; a::text&#39;)[1].get() . # xpath response.xpath(&#39;//div[@class=&quot;best-list&quot;]/ul/li/a&#39;).getall() response.xpath(&#39;//div[@class=&quot;best-list&quot;]/ul/li/a/text()&#39;).getall() . # re 정규표신혁 # n은 파이썬 3.0 이상은 한글도 포함 but reg 홈페이지에는 반영 안되어 있음 response.css(&#39;div.best-list li &gt; a::text&#39;)[1].re(&#39;( w+)&#39;) response.xpath(&#39;//div[@class=&quot;best-list&quot;]/ul/li/a/text()&#39;)[1].re(&#39;( w+)&#39;) . Excel . import win32com.client as win32 excel = win32.gencache.EnsureDispatch(&#39;Excel.Application&#39;) wb = excel.Workbooks.Add() ws = wb.Sheets(&quot;Sheet1&quot;) rng = ws.Range(&quot;B2&quot;) image = ws.Shapes.AddPicture(r&quot;C: Users tgkang Documents 크롤링2 103 image0.jpg&quot;, False, True, rng.Left, rng.Top, 100, 100) excel.Visible=True . openpyxl . 패턴 . # 엑셀 파일 읽기 import openpyxl excel_file = openpyxl.load_workbook(&#39;tmp.xlsx&#39;) excel_sheet = excel_file.active # excel_sheet = excel_file.get_sheet_by_name(&#39;IT뉴스&#39;) # 데이터 읽기 for row in excel_sheet.rows: print(row[0].value, row[1].value) excel_file.close() . Syntax . # 파일 가져오기 excel_file = openpyxl.load_workbook(r&#39;C: Users tgkang Documents 크롤링1 tmp.xlsx&#39;) # 파일 생성 excel_file = openpyxl.Workbook() # 활성화 excel_sheet = excel_file.active # 시트 이름 excel_sheet.title = &#39;testsheet&#39; # 시트 선택 excel_sheet = excel_file[&quot;상품정보&quot;] # sheet name 확인하기 excel_file.sheetnames # 컬럼 크기 변경 excel_sheet.column_dimensions[&#39;A&#39;].width = 100 excel_sheet.column_dimensions[&#39;B&#39;].width = 20 # 데이터 입력 excel_sheet.append([&quot;하이&quot;]) # 파일 저장 excel_file.save(&quot;피카피카.xlsx&quot;) # 파일 닫기 excel_file.close() . 이미지 . import win32com.client as win32 excel = win32.gencache.EnsureDispatch(&#39;Excel.Application&#39;) wb = excel.Workbooks.Add() ws = wb.Sheets(&quot;Sheet1&quot;) rng = ws.Range(&quot;B2&quot;) image = ws.Shapes.AddPicture(r&quot;C: Users tgkang Documents 크롤링2 103 image0.jpg&quot;, False, True, rng.Left, rng.Top, 100, 100) excel.Visible=True . openAPI . naver . 기본 패턴 . import requests import pprint client_id = &#39;BTMVavws8Is7jmVpUcSL&#39; client_secret = &#39;sDgiapg86l&#39; naver_open_api = &#39;https://openapi.naver.com/v1/search/shop.json?query=갤럭시노트10&#39; header_params = {&quot;X-Naver-Client-Id&quot;:client_id, &quot;X-Naver-Client-Secret&quot;:client_secret} res = requests.get(naver_open_api, headers=header_params) # header에 아이디 넣어보냄 if res.status_code == 200: data = res.json() for index, item in enumerate(data[&#39;items&#39;]): print (index + 1, item[&#39;title&#39;], item[&#39;link&#39;]) else: print (&quot;Error Code:&quot;, res.status_code) . 엑셀 저장 . import requests import openpyxl client_id = &#39;CgZgjTdS7F2naaLEhWRg&#39; client_secret = &#39;oCwEtEw08Y&#39; start, num = 1, 0 # 시작 페이지, 인덱스 설정 excel_file = openpyxl.Workbook() excel_sheet = excel_file.active excel_sheet.column_dimensions[&#39;B&#39;].width = 100 # 셀 너비 조정 excel_sheet.column_dimensions[&#39;C&#39;].width = 100 excel_sheet.append([&#39;랭킹&#39;, &#39;제목&#39;, &#39;링크&#39;]) for index in range(10): start_number = start + (index * 100) naver_open_api = &#39;https://openapi.naver.com/v1/search/shop.json?query=샤오미&amp;display=100&amp;start=&#39; + str(start_number) header_params = {&quot;X-Naver-Client-Id&quot;:client_id, &quot;X-Naver-Client-Secret&quot;:client_secret} res = requests.get(naver_open_api, headers=header_params) if res.status_code == 200: data = res.json() for item in data[&#39;items&#39;]: num += 1 excel_sheet.append([num, item[&#39;title&#39;], item[&#39;link&#39;]]) else: print (&quot;Error Code:&quot;, res.status_code) excel_file.save(&#39;IT.xlsx&#39;) excel_file.close() . 정규화 . 문자열 처리 . # 특정 문자 넣기 string = &quot;12345&quot; comma = &#39;,&#39; comma.join(string) . &#39;1,2,3,4,5&#39; . # 특정 문자외 제거 string = &quot; 9999999999999999(Dave)888888888888888888 &quot; string.strip(&quot; 98()&quot;) # 앞 뒤 괄호를 다 지움 . &#39;Dave&#39; . # 문자열 나누기 - 인덱스 string = &quot;Dave goes to Korea&quot; string.split()[3] . &#39;Korea&#39; . 정규식 . 정규 표현식 축약 표현 사용 예 . [0-9] | d | 숫자를 찾음 | . [^0-9] | D | 숫자가 아닌 것을 찾음(텍스트, 특수 문자, white space(스페이스, 탭, 엔터 등등)를 찾을 때) | . [ t n r f v] | s | white space(스페이스, 탭, 엔터 등등) 문자인 것을 찾음 | . [^ t n r f v] | S | white space(스페이스, 탭, 엔터 등등) 문자가 아닌 것을 찾음(텍스트, 특수 문자, 숫자를 찾을 때) | . [A-Za-z0-9] | w | 문자, 숫자를 찾음 | . [^A-Za-z0-9] | W | 문자, 숫자가 아닌 것을 찾음 | . sub . # re.sub string = &#39;(초급) - 강사가 실제 사용하는 자동 프로그램 소개 [2]&#39; import re print(re.sub(&#39; [[0-9]+ ]&#39;, &#39;&#39;, string)) print(re.sub(&#39;프로그램&#39;, &#39;모듈&#39;, string)) # 찾아 바꾸기 . (초급) - 강사가 실제 사용하는 자동 프로그램 소개 (초급) - 강사가 실제 사용하는 자동 모듈 소개 [2] . import re pattern2 = re.compile(&#39;-&#39;) subed = pattern2.sub(&#39;*&#39;, &#39;801210-1011323&#39;) # sub(바꿀문자열, 본래문자열) subed . &#39;801210*1011323&#39; . pattern . # pattern 적용 pattern = re.compile(&#39;D.A&#39;) # .은 모든 숫자 및 문자 print(pattern.search(&quot;DAA&quot;)) # 해당 print(pattern.search(&quot;D1A&quot;)) # 해당 print(pattern.search(&quot;D00A&quot;)) # 해당 x print(pattern.search(&quot;d0A&quot;)) # 해당 x print(pattern.search(&quot;d0A D1A 0111&quot;)) # 해당 . &lt;re.Match object; span=(0, 3), match=&#39;DAA&#39;&gt; &lt;re.Match object; span=(0, 3), match=&#39;D1A&#39;&gt; None None &lt;re.Match object; span=(4, 7), match=&#39;D1A&#39;&gt; . # 특수문자 적용 사용 pattern = re.compile(&#39;D .A&#39;) # 정말 기호 적용 print(pattern.search(&quot;D.A&quot;)) # 해당 print(pattern.search(&quot;DDA&quot;)) # 해당 x . &lt;re.Match object; span=(0, 3), match=&#39;D.A&#39;&gt; None . # 특수문자 적용 [] 사용 pattern = re.compile(&#39;D[.]A&#39;) # 정말 기호 적용 print(pattern.search(&quot;D.A&quot;)) # 해당 print(pattern.search(&quot;DDA&quot;)) # 해당 x . &lt;re.Match object; span=(0, 3), match=&#39;D.A&#39;&gt; None . match 와 search 함수 . match : 문자열 처음부터 정규식과 매칭되는 패턴을 찾아서 리턴 | search : 문자열 전체를 검색해서 정규식과 매칭되는 패턴을 찾아서 리턴 | . import re pattern = re.compile(&#39;[a-z]+&#39;) matched = pattern.match(&#39;Dave&#39;) print(matched) searched = pattern.search(&quot;Dave&quot;) print(searched) . None &lt;re.Match object; span=(1, 4), match=&#39;ave&#39;&gt; . findall . 정규표현식과 매칭되는 모든 문자열을 리스트 객체로 리턴함 . import re pattern = re.compile(&#39;[a-z]+&#39;) findalled = pattern.findall(&#39;Game of Life in Python&#39;) print (findalled) . [&#39;ame&#39;, &#39;of&#39;, &#39;ife&#39;, &#39;in&#39;, &#39;ython&#39;] . # findall 활용 import re pattern = re.compile(&#39;[a-z]+&#39;) findalled = pattern.findall(&#39;GAME&#39;) if len(findalled) &gt; 0: print (&quot;정규표현식에 맞는 문자열이 존재함&quot;) else: print (&quot;정규표현식에 맞는 문자열이 존재하지 않음&quot;) . 정규표현식에 맞는 문자열이 존재하지 않음 . split . import re pattern2 = re.compile(&#39;:&#39;) splited = pattern2.split(&#39;python:java&#39;) splited . [&#39;python&#39;, &#39;java&#39;] . ? , * , + . ? 는 앞 문자가 0번 또는 1번 표시되는 패턴 (없어도 되고, 한번 있어도 되는 패턴) | * 는 앞 문자가 0번 또는 그 이상 반복되는 패턴 | + 는 앞 문자가 1번 또는 그 이상 반복되는 패턴 | . pattern = re.compile(&#39;D?A&#39;) print(pattern.search(&quot;A&quot;)) print(pattern.search(&quot;DA&quot;)) print(pattern.search(&quot;DDDDDDA&quot;)) . &lt;re.Match object; span=(0, 1), match=&#39;A&#39;&gt; &lt;re.Match object; span=(0, 2), match=&#39;DA&#39;&gt; &lt;re.Match object; span=(5, 7), match=&#39;DA&#39;&gt; . pattern = re.compile(&#39;D*A&#39;) print(pattern.search(&quot;DA&quot;)) print(pattern.search(&quot;DDDDDDDDDDDDDDDDDDDDDDDDDDDDA&quot;)) . &lt;re.Match object; span=(0, 1), match=&#39;A&#39;&gt; &lt;re.Match object; span=(0, 2), match=&#39;DA&#39;&gt; &lt;re.Match object; span=(0, 29), match=&#39;DDDDDDDDDDDDDDDDDDDDDDDDDDDDA&#39;&gt; . {n}, {m,n} . {n} : 앞 문자가 n 번 반복되는 패턴 | {m, n} : 앞 문자가 m 번 반복되는 패턴부터 n 번 반복되는 패턴까지 | . # {n} pattern = re.compile(&#39;AD{2}A&#39;) print(pattern.search(&quot;ADA&quot;)) print(pattern.search(&quot;ADDA&quot;)) print(pattern.search(&quot;ADDDA&quot;)) . None &lt;re.Match object; span=(0, 4), match=&#39;ADDA&#39;&gt; None . # {m,n} pattern = re.compile(&#39;AD{2,6}A&#39;) # {m,n} 은 붙여 써야 함 {m, n} 으로 쓰면 안됨(특이함) print(pattern.search(&quot;ADDA&quot;)) print(pattern.search(&quot;ADDDA&quot;)) print(pattern.search(&quot;ADDDDDDA&quot;)) . &lt;re.Match object; span=(0, 4), match=&#39;ADDA&#39;&gt; &lt;re.Match object; span=(0, 5), match=&#39;ADDDA&#39;&gt; &lt;re.Match object; span=(0, 8), match=&#39;ADDDDDDA&#39;&gt; . [ ] 괄호 내 문자 . 예: [abc] 는 a, b, c 중 하나가 들어 있는 패턴을 말함 | . pattern = re.compile(&#39;[abcdefgABCDEFG]&#39;) print(pattern.search(&quot;a1234&quot;)) print(pattern.search(&quot;z1234&quot;) ) . &lt;re.Match object; span=(0, 1), match=&#39;a&#39;&gt; None . [a-zA-Z0-9] . pattern = re.compile(&#39;[a-zA-Z0-9]&#39;) print(pattern.search(&quot;1234&quot;) ) print(pattern.search(&quot;!@#!@$!$%#%%%#%%@$!$!&quot;) ) . [^] . pattern = re.compile(&#39;[^a-zA-Z0-9]&#39;) pattern.search(&quot;!@#!@$!$%#%%%#%%@$!$!&quot;) . &lt;re.Match object; span=(0, 1), match=&#39;-&#39;&gt; . pattern = re.compile(&#39;[^ t n r f v]&#39;) pattern.search(&quot;-&quot;) . 가-힣 . pattern = re.compile(&#39;[가-힣]&#39;) pattern.search(&quot;안&quot;) . &lt;re.Match object; span=(0, 1), match=&#39;안&#39;&gt; . 활용예제 . # 주민 등록 번호 import openpyxl work_book = openpyxl.load_workbook(r&#39;C: Users tgkang Documents 크롤링1 data_kr.xlsx&#39;) work_sheet = work_book.active for each_row in work_sheet.rows: print(re.sub(&#39;-[0-9]{7}&#39;, &#39;-*******&#39;, each_row[1].value)) work_book.close() . 주민등록번호 800215-******* 821030-******* 841230-******* 790903-******* 800125-******* 820612-******* . import requests from bs4 import BeautifulSoup . . 1 [대우]대우 에어 써큘레이터DEF-KC1020스탠드선풍기 공기순환 - 35,900원 2 [위닉스](공식인증점) 위닉스 뽀송 제습기 10리터 DXAE100-JWK - 229,000원 3 [대웅모닝컴](행사) 대웅모닝컴 14형 스탠드 선풍기 (신제품 입고) - 29,900원 4 [마이크로소프트]Xbox 충전식 배터리 +USB C타입 케이블 - 29,800원 5 숲속바람 스탠드 선풍기 2022 신형 가정용선풍기 14형 - 29,900원 6 [뽀송]공식인증점)위닉스 NEW 17L 제습기 DN3E170-LWK 1등급 - 379,000원 7 [대웅모닝컴]대웅 3D 입체회전 리모컨 스탠드 써큘레이터 선풍기 - 39,800원 8 [신일전자][신일] [화이트] 에어서큘레이터(SIF-FA800B) - 109,200원 9 [윈드피아](특가) 22년형 가정용 업소용 스탠드선풍기 WA-170 - 29,900원 10 [르젠]내일도착르젠2세대 앱연동 BLDC 선풍기 LZEF-DC180 화이트 - 69,800원 11 [대웅모닝컴]대웅 가정용 스탠드선풍기 키높이선풍기 - 28,800원 12 [휘센]LG전자 휘센 제습기 DQ202PGUA (OK) - 619,000원 13 [보본]무선 캠핑 선풍기 탁상용 휴대용 캠핑용 타프팬 - 39,900원 14 [신일전자]신일 기본형 선풍기 10% 다운로드 쿠폰 - 57,900원 15 [르젠]22년형+15%쿠폰) 르젠 APP연동 좌우회전 저소음 선풍기 - 79,800원 16 [신일][신일] 2022년형 BLDC air S8 써큘레이터 (베이지/딥그린/라이트핑크) - 134,400원 17 [윈드피아]가정용 업소용 스탠드 리모컨 선풍기 인기상품 1700R - 36,900원 18 [한일]한일 2022년 신상품 35cm 기계식선풍기 EFe-G014 - 44,900원 19 [위닉스](공식인증점) 위닉스 제습기 16리터 DO2E160-JWK - 359,000원 20 [뽀송]공식인증) 위닉스 1등급 제습기 16리터 DN2H160-IWK - 359,000원 21 [르젠]22년형+10%쿠폰) 르젠 리모컨 써큘레이터 저소음 선풍기 LZEF-AR03 - 49,800원 22 [신일전자]프리미엄 BLDC 써큘레이터형 스탠드 선풍기 SIF-T14SH - 139,900원 23 [위닉스]10%쿠폰)인증점 위닉스 뽀송 제습기 10L DXAH100-JWK - 219,000원 24 [위닉스](인증점)위닉스 뽀송 제습기 16리터 DO2E160-JWK 1등급 - 359,000원 25 [솔러스에어]1+1 2개 무선 선풍기 탁상용 미니 휴대용 캠핑 벽걸이 - 59,900원 26 [뽀송]공식인증점)위닉스 NEW 17L 제습기 DN3E170-LWK 1등급 - 409,000원 27 [삼성전자]삼성 윈도우핏 에어컨 길이 연장 키트 60cm - 85,000원 28 [엔보우]모노 탁상용 무선 휴대용 선풍기 2세대 1+1(할인 행사) - 29,900원 29 [통돌이]갤러리아 LG 일반 세탁기 TR12WL 12kg/화이트 - 383,000원 30 [신일전자]신일 14형 좌석용 선풍기 SIF-14HKW 신일선풍기 4엽 - 62,000원 31 [위닉스](공식인증점) 위닉스 뽀송 제습기 10L DXAH100-JWK - 237,000원 32 [필립스]PHILIPS 전기면도기 SkinIQ 5000 S5582/36 오션블루 - 159,000원 33 [자우버]렌즈케어 200매 렌즈클리너 일회용 안경닦이 티슈 - 9,030원 34 [숲속바람]Forest Wind 저소음 5엽 스탠드 선풍기 2022신상품 - 32,580원 35 [신일전자][신일] (인기모델)[블랙] 에어서큘레이터(SIF-FB500A) - 101,200원 36 [제이닉스]제이닉스 14인치 스탠드 선풍기 가정용 JYF-KN4523 - 29,800원 37 [샤오미]미밴드7 한글판 AOD탑재 공식수입 블랙/국내AS가능 - 59,800원 38 [LG전자]LG전자 휘센 제습기 20L DQ202PGUA - 699,000원 39 [쿠쿠]본사직영 20L 전자레인지 CMW-A201DW 화이트 - 56,000원 40 크레마 S (crema S) 블랙 / 화이트 - 199,000원 41 [위닉스]DXSM170-IWK 위닉스 뽀송 제습기 17L / LK - 372,750원 42 [삼성전자]갤럭시 A53 5G SM-A536N 128G 자급제 _RM - 507,130원 43 [제이엠더블유]JMW M5001A PLUS BLDC 드라이기 거치대 세트+스타벅스 - 81,000원 44 [로보락](혜택가149만원) 로보락 S7 MaxV Ultra 로봇청소기 울트라 자동세척 - 1,590,000원 45 [위닉스][공식파트너]위닉스 뽀송 10리터 제습기 DXAE100-JWK - 227,940원 46 [레드울프]S22 노트20/노트10/S21/S20/S10/A53/A32 울트라 가죽 - 19,900원 47 [삼성전자]삼성 갤럭시버즈2 블루투스 이어폰 SM-R177 - 94,640원 48 [모이스]추가 10%쿠폰) 고급형 미니 제습기 저소음 소형 원룸 사무실 작은방 - 49,900원 49 [삼성전자]삼성전자 DDR4 16G PC4-25600 (정품)-PL - 76,890원 50 [에코백스]쿠폰 139만원) (비밀쿠폰)에코백스 X1 옴니 로봇청소기 듀얼스테이션 - 1,590,000원 51 S22 울트라 노트20/노트10/S21/S20/A53 A32 A23 가죽 - 19,900원 52 [르젠][르젠] [빠른배송] 22년 신상 리모컨 써큘레이터 선풍기 LZEF-DC260 - 69,800원 53 [캐리어]6평형 인버터 벽걸이 에어컨 ORCD061FAWWSD 22년최신형 - 529,000원 54 [위니아]인증 위니아 가정용제습기 EDH8DNWB 8L - 175,020원 55 [유닉스]메탈티 무광블랙 1600W 헤어 드라이기 UN-A1610 접이식 - 23,900원 56 유니맥스 UMF-R5314LDC 12단 BLDC모터 서큘형 선풍기 - 72,900원 57 [테팔](10%중복할인) 블렌더 믹서기 블렌드포스 플러스 BL4258 - 42,900원 58 CAXA UP 이영애 카사업 하트 페이스 탄력 기기 x 가히 에센스 - 189,000원 59 [비달사순]비달사순 2000W 전문가용 헤어드라이기 VSD5129K - 22,800원 60 [일렉트로룩스]파워PRO 18V 무선청소기 ZB3411 (BEST 인기) - 169,000원 61 [르젠]22년형+15%쿠폰) 르젠 APP연동 입체회전 저소음 선풍기 LZDF-TR08 - 89,800원 62 [쿠쿠]본사직영 CRP-CHP1010FD 10인용 IH전기압력 밥솥 - 249,000원 63 [로지텍]로지텍코리아 정품 무선 마우스 MX MASTER 3S /무소음 - 139,000원 64 [샤오미]MI 스마트 무선 선풍기 4세대 프로 PRO + MI FAN2 PRO - 111,300원 65 [솔러스에어]1+1 2개 세트 휴대용 미니 무선 탁상용 캠핑 선풍기 - 54,900원 66 [위닉스]공식인증점 2022년 신상품 제습기 17L DN3E170-LWK 1등급 뽀송 - 422,490원 67 [휘센]LG전자 휘센 제습기 DQ162PGUA (OK) - 509,400원 68 [신일전자]신일 강화유리 무선 전기주전자 SEP-GW90 - 28,000원 69 [노브랜드]노브랜드 표준형 선풍기 (FN280N) - 34,800원 70 [레노버]레노버 아이디어패드 Slim3 14ALC R5DOS4GB 샌드 41만 - 469,650원 71 [삼성전자]846리터 3도어 양문형 냉장고 RS84T5041M9 공식인증점 - 1,199,000원 72 [삼성전자]인버터 제습기 AY18BG7500GBD 1등급 혜택가 37.9만원 - 407,520원 73 [신일전자]신일 12인치 선풍기 SIF-12MMC 5엽 가정용 스탠드형 - 49,800원 74 [한경희생활과학]한경희생활과학 스탠드 스팀다리미 HESI-D1600WT - 129,000원 75 [스카이]핏 S 미니 블루투스 5.3 오픈형 무선이어폰 - 29,800원 76 [쿠쿠](혜택가 92650원) 본사직영 BLDC 서큘레이터 선풍기 CF-AC1410WH - 109,000원 77 핸드폰 갤럭시S22울트라 S21 S20 노트20 노트10 노트9 - 9,900원 78 [파세코]파세코 접이식 12인치 써큘레이터 PDF-MSFB1120W - 119,000원 79 [SK매직]20L 전자레인지 MWO-20M8A01 1년 무상A/S - 63,700원 80 [퀸메이드]초절전 BLDC 리모컨 선풍기 제로 써큘레이터 화이트 - 69,900원 81 삼성전자 DDR4 8G PC4-25600 (정품)-PL - 35,270원 82 [삼성전자]삼성 윈도우핏 에어컨 길이 연장 키트 90cm - 109,000원 83 [쿠쿠]본사직영 CRP-HQB0310FS 3인용 IH전기압력 밥솥 - 135,000원 84 [위닉스]DXJH193-KWK 뽀송 제습기 19L 81.5㎡/LK - 489,020원 85 [삼성전자]삼성 갤럭시버즈 프로 ANC 블루투스 이어폰 SM-R190 - 139,000원 86 [신일전자][신일] 2022NEW [베이지] BLDC 에어서큘레이터 AIR S8 (SIF-T09B - 129,400원 87 [신일전자]신일 선풍기 SIF-P14PCB 스탠드형 써큘레이터형 - 64,900원 88 [뽀송]공식인증점)위닉스 17L제습기 {DN3E170-LWK} NEW/1등급 - 430,000원 89 삼성 스탠드 선풍기 SFN-T35GFST - 88,990원 90 [신일전자]초미풍 스탠드 선풍기 SIF-D14BS 혜택가 59420원 - 69,900원 91 [삼성전자]오디세이 G5 C34G55T 86.4cm 게이밍모니터 165Hz - 599,000원 92 [윈드피아]가정용선풍기 업소용선풍기 스탠드 선풍기 WA-370블랙 - 23,900원 93 [삼성전자]삼성전자 WindowFit 창문형에어컨 AW05A5171EZA /MS - 551,000원 94 [샤오미]미밴드7 블랙 한글판 스트랩증정 국내AS - 59,800원 95 [삼성전자]삼성 공식인증 MicroSD EVO Plus 512GB MB-MC512KA EL - 58,710원 96 [위닉스]_위닉스 인버터 제습기 19L 1등급 DXJH193-KWK - 499,000원 97 [로이체]바람쎈 에어 써큘레이터/선풍기 RC-50 - 34,900원 98 [신일전자]신일 BLDC 무소음 리모컨 선풍기 SIF-DC514NK - 125,100원 99 [신일전자]BLDC 입체회전 써큘레이터 SIF-DPNW90 혜택가 - 149,000원 100 [쿠쿠]본사직영 20리터 전자레인지 CMW-A201DB 블랙 - 56,000원 &quot; ndd = [&#39;가&#39;] nfor item in dd: n print(dd) n&quot; .",
            "url": "https://tg0708.github.io/testcolabblog/2022/07/05/code.html",
            "relUrl": "/2022/07/05/code.html",
            "date": " • Jul 5, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "제목!!",
            "content": "from tqdm import tqdm from bs4 import BeautifulSoup import requests import re import pandas as pd col = [&#39;날짜&#39;, &#39;카테고리&#39;, &#39;홈사&#39;,&#39;시간&#39;,&#39;타이틀&#39;,&#39;제품가&#39;,&#39;이미지&#39;] df = pd.DataFrame(columns=col) date = input(&#39;날짜를 입력하세요 : &#39;) res = requests.get(f&#39;https://www.hsmoa.com/?date={date}&amp;site=&amp;cate=&#39;) res.status_code soup = BeautifulSoup(res.content, &quot;html.parser&quot;) item_list = [] category_list = [] shopmall_list = [] time_list = [] price_list = [] container = soup.select(&#39;div.timeline-item&#39;) for idx, item in tqdm(enumerate(container)): # 상품 item_content = item.select_one(&#39;.font-15&#39;).text.strip() item_list.append(item_content) # 문자화 make_str = str(item) make_str = make_str.split(&#39;&gt;&#39;)[0] # 쇼핑사 shopmall_content = make_str.split(&#39;timeline-item &#39;)[1].split(&quot; &quot;)[0] shopmall_list.append(shopmall_content) # 카테고리 분류 p = re.compile(&#39;[가-힣]&#39;) result = p.findall(make_str) category_content = &quot;&quot;.join(result) category_list.append(category_content) # 시간0 try : time_contents = item.select_one(&#39;.font-12&#39;).text.strip() time_start = time_contents.split(&quot; n&quot;)[0] time_end = time_contents.split(&quot; n&quot;)[1].strip() time_content = time_start + time_end time_list.append(time_content) except: time_content = &quot;-&quot; # 가격 price_contents = item.select_one(&#39;.strong.font-17&#39;).text.strip() # 이미지 str_img = str(item.select_one(&#39;img.lazy&#39;)) img_content = str_img.split(&#39;smart/&#39;)[1].split(&#39;&quot;&#39;)[0] # 딕셔너리 dict_info = {&#39;날짜&#39;:date, &#39;카테고리&#39;: category_content,&#39;홈사&#39;:shopmall_content, &#39;시간&#39;:time_content,&#39;타이틀&#39;:item_content,&#39;제품가&#39;:price_contents,&#39;이미지&#39;:img_content} df = df.append(dict_info, ignore_index=True) # 엑셀 내보내기 df.to_excel(&quot;쇼핑몰데이터.xlsx&quot;) df . 날짜를 입력하세요 : 20220626 . 429it [00:02, 148.21it/s] . 날짜 카테고리 홈사 시간 타이틀 제품가 이미지 . 0 20220626 | 가전디지털 | nsmallplus | 0시 03분 ~0시 43분 | 휴라이즈 턴테이블 프리미엄형(HR-TS200) | 274,000원 | http://cdn.image.buzzni.com/2022/06/17/dXFH3Ku... | . 1 20220626 | 패션잡화 | wshop | 0시 25분 ~1시 26분 | [릴리전]베이직 코튼 100 티셔츠 9종세트(남여공용) | 28,900원 | http://cdn.image.buzzni.com/2022/06/23/VaLU0nX... | . 2 20220626 | 식품건강 | ssgshop | 0시 27분 ~1시 27분 | [이번달 단 하루 1개월분 더] 종근당건강 프로메가 알티지오메가3 듀얼 12+1개월... | 168,600원 | http://cdn.image.buzzni.com/2022/04/20/o47SfAq... | . 3 20220626 | 패션잡화 | kshopplus | 0시 35분 ~1시 36분 | 엘르 플라워 펀칭 샌들(여) | 54,510원 | http://cdn.image.buzzni.com/2022/06/14/pmpdXn3... | . 4 20220626 | 여행레저 | bshop | 0시 36분 ~1시 36분 | [바른투어] (상담예약만)울릉도/독도/관음도 3일 여행(7~9월) | 상담/렌탈 | http://cdn.image.buzzni.com/2022/06/10/FOVZNEy... | . ... ... | ... | ... | ... | ... | ... | ... | . 424 20220626 | 생활주방 | hmall | 23시 50분 ~1시 00분 | 라클라우드 이태리 천연라텍스 매트리스 렌탈 | 상담/렌탈 | http://cdn.image.buzzni.com/2022/05/17/FhAnDp2... | . 425 20220626 | 가전디지털 | hnsmall | 23시 50분 ~1시 00분 | [방송][TV CF동일] 유라이크 사파이어 쿨링 셀프제모기 (의료기기 UI-04M) | 358,200원 | http://cdn.image.buzzni.com/2022/06/27/kr1eRYC... | . 426 20220626 | 생활주방 | lottemall | 23시 50분 ~1시 00분 | 바디프랜드 안마의자 렌탈 | 상담/렌탈 | http://cdn.image.buzzni.com/2022/05/10/PF6mJJh... | . 427 20220626 | 식품건강 | nsmall | 23시 50분 ~1시 00분 | 빨간스캔들 유기농석류 240포 | 134,500원 | http://cdn.image.buzzni.com/2022/06/22/SeqDKbJ... | . 428 20220626 | 식품건강 | immall | 23시 55분 ~1시 00분 | [무료체험7팩] 제주콩생나또(1+1세트)_68팩 | 45,900원 | http://cdn.image.buzzni.com/2022/03/05/gX4vp3r... | . 429 rows × 7 columns . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt;",
            "url": "https://tg0708.github.io/testcolabblog/scrapping/jupyter/2022/07/05/_07_04_mall.html",
            "relUrl": "/scrapping/jupyter/2022/07/05/_07_04_mall.html",
            "date": " • Jul 5, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "coding_주피터노트북!!",
            "content": "Warnings . import warnings warnings.filterwarnings(&#39;ignore&#39;) . Bs4 . &#54056;&#53556; . &#44592;&#48376; &#54056;&#53556; . # find import requests from bs4 import BeautifulSoup res = requests.get(&quot;크롤링 할 주소&quot;) soup = BeautifulSoup(res.content, &quot;html.parser&quot;) mydata = soup.find(&#39;title&#39;) print(mydata.text) . # select import requests from bs4 import BeautifulSoup res = requests.get(&#39;https://davelee-fun.github.io/blog/crawl_test_css.html&#39;) soup = BeautifulSoup(res.content, &#39;html.parser&#39;) items = soup.select(&#39;li&#39;) for item in items: print (item.get_text()) . &#51025;&#45813; &#54168;&#51060;&#51648; &#54869;&#51064; . import requests from bs4 import BeautifulSoup res = requests.get(&#39;https://davelee-fun.github.io/xxx&#39;) if res.status_code != 200: print (&#39;페이지 없음&#39;) else: soup = BeautifulSoup(res.content, &#39;html.parser&#39;) data = soup.select(&#39;h4.card-text&#39;) for item in data: print (item.get_text()) . &#50668;&#47084; &#54168;&#51060;&#51648; . import requests from bs4 import BeautifulSoup for page_num in range(10): if page_num == 0: res = requests.get(&#39;https://davelee-fun.github.io/&#39;) else: res = requests.get(&#39;https://davelee-fun.github.io/page&#39; + str(page_num + 1)) soup = BeautifulSoup(res.content, &#39;html.parser&#39;) data = soup.select(&#39;h4.card-text&#39;) for item in data: print (item.get_text().strip()) . &#50641;&#49472; &#51200;&#51109; . ! pip install openpyxl . Requirement already satisfied: openpyxl in c: users tgkang anaconda3 lib site-packages (3.0.9) Requirement already satisfied: et-xmlfile in c: users tgkang anaconda3 lib site-packages (from openpyxl) (1.1.0) . import openpyxl def write_excel_template(filename, sheetname, listdata): excel_file = openpyxl.Workbook() excel_sheet = excel_file.active excel_sheet.column_dimensions[&#39;A&#39;].width = 100 excel_sheet.column_dimensions[&#39;B&#39;].width = 20 if sheetname != &#39;&#39;: excel_sheet.title = sheetname for item in listdata: excel_sheet.append(item) excel_file.save(filename) excel_file.close() . import requests from bs4 import BeautifulSoup product_lists = list() for page_num in range(10): if page_num == 0: res = requests.get(&#39;https://davelee-fun.github.io/&#39;) else: res = requests.get(&#39;https://davelee-fun.github.io/page&#39; + str(page_num + 1)) soup = BeautifulSoup(res.content, &#39;html.parser&#39;) data = soup.select(&#39;div.card&#39;) for item in data: product_name = item.select_one(&#39;div.card-body h4.card-text&#39;) product_date = item.select_one(&#39;div.wrapfooter span.post-date&#39;) product_info = [product_name.get_text().strip(), product_date.get_text()] # 리스트 product_lists.append(product_info) write_excel_template(&#39;tmp.xlsx&#39;, &#39;상품정보&#39;, product_lists) . find . data = soup.find(&#39;p&#39;, class_=&#39;cssstyle&#39;) # 태그, 클래스 data = soup.find(&#39;p&#39;, &#39;cssstyle&#39;) # 태그, 클래스 data = soup.find(&#39;p&#39;, attrs = {&#39;align&#39;: &#39;center&#39;}) # 태그, 속성 data = soup.find(id=&#39;body&#39;) # 아이디 data = soup.find(&#39;h3&#39;,&#39;tit_view&#39;) data = soup.find(&#39;div&#39;, &#39;layer_util layer_summary&#39;) . select . items = soup.select(&#39;.course&#39;) # 클래스 items = soup.select(&#39;#start&#39;) # 아이디 items = soup.select(&#39;td[valign=&quot;top&quot;]&#39;) # 태그, 특정 속성 items = soup.findAll(&quot;td&quot;, {&quot;valign&quot; : re.compile(r&quot;.*&quot;)}) # 정규 표현식 items = soup.select(&#39;li.course.paid&#39;) # 태그, 클래스1, 클래스2 items = soup.select(&#39;html body h1&#39;) # 하위 태그 items = soup.select(&#39;ul &gt; li&#39;) # 직계 하위 태그 items = soup.select(&#39;ul#hobby_course_list li.course&#39;) # 태그, 아이디, 하위 태그, 클래스 item = soup.select_one(&#39;ul#dev_course_list &gt; li.course.paid&#39;) . &#54876;&#50857;&#50696;&#51228; . # G마켓 베스트 상품 url = &quot;http://corners.gmarket.co.kr/Bestsellers?viewType=G&amp;groupCode=G06&quot; res = requests.get(url) if res.status_code != 200: print(&quot;응답 없음&quot;) else : soup = BeautifulSoup(res.content, &#39;html.parser&#39;) bestlist = soup.select(&#39;.best-list li&#39;) for idx, item in enumerate(bestlist): item_list = item.select_one(&#39;div .itemname&#39;).text.strip() price_list = item.select_one(&#39;div .s-price span&#39;).text.strip() print(idx+1,item_list,&quot; - &quot;, price_list) . Selenium . &#44592;&#48376; &#54056;&#53556; . from selenium import webdriver from selenium.webdriver.common.keys import Keys from selenium.webdriver.common.by import By from selenium.webdriver.chrome.service import Service from webdriver_manager.chrome import ChromeDriverManager import time # 드라이버 생성 # chromedriver 설치된 경로를 정확히 기재해야 함 chromedriver = r&#39;C: Users tgkang Documents 크롤링2 103 chromedriver.exe&#39; driver = webdriver.Chrome(service=Service(chromedriver)) . Autoinstaller . from selenium import webdriver import chromedriver_autoinstaller import os from selenium.webdriver.common.by import By from selenium.webdriver.chrome.service import Service from webdriver_manager.chrome import ChromeDriverManager # Check if chrome driver is installed or not chrome_ver = chromedriver_autoinstaller.get_chrome_version().split(&#39;.&#39;)[0] driver_path = f&#39;./{chrome_ver}/chromedriver.exe&#39; if os.path.exists(driver_path): print(f&quot;chrom driver is insatlled : {driver_path}&quot;) else: print(f&quot;install the chrome driver(ver : {chrome_ver})&quot;) chromedriver_autoinstaller.install(True) driver = webdriver.Chrome(service=Service(driver_path)) . Options . from selenium import webdriver from selenium.webdriver.chrome.options import Options import warnings import chromedriver_autoinstaller warnings.filterwarnings(&#39;ignore&#39;) options = Options() options.add_argument(&#39;headless&#39;) # headless 모드 options.add_argument(&#39;window-size=1920*1080&#39;) options.add_argument(&#39;--start-maximized&#39;) # 최대화 options.add_argument(&#39;--start-fullscreen&#39;) # 풀스크린 코드 options.add_argument(&#39;--mute-audio&#39;) #브라우저에 음소거 옵션을 적용합니다. options.add_argument(&#39;incognito&#39;) #시크릿 모드의 브라우저가 실행됩니다. options.add_argument(&#39;disable-gpu&#39;) options.add_argument(&#39;User-Agent:Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36&#39;) options.add_argument(&#39;lang=ko-KR&#39;) # 자동화 문구 제거 options.add_experimental_option(&quot;useAutomationExtension&quot;, False) options.add_experimental_option(&quot;excludeSwitches&quot;, [&#39;enable-automation&#39;]) # 디버거 모드 - 안됨 options.add_experimental_option(&quot;debuggerAddress&quot;, &quot;127.0.0.1:9222&quot;) driver_path = &#39;./103/chromedriver.exe&#39; driver = webdriver.Chrome(executable_path= driver_path, options= options) . Driver . Assert . # Selenium은 웹테스트를 위한 프레임워크로 다음과 같은 방식으로 웹테스트를 자동으로 진행함 (참고) print (driver.title) assert &quot;Teddy&quot; in driver.title . Size . # 웹페이지 전체 사이즈 driver.maximize_window() # 웹페이지 전체 사이즈 driver.minimize_window() # 웹페이지 사이즈 조절 driver.set_window_size(1000,1000) # 풀스크린 driver.fullscreen_window() . Handle . # 현재 핸들중인 창 목록 조회 driver.window_handles driver.window_handles[0] # 첫번째 창 driver.window_handles[1] # 두번째 창 driver.window_handles[-1] # 가장 최근에 열린창 . Switch . # switch driver.switch_to.window(driver.window_handles[1]) # iframe으로 이동 driver.switch_to.frame(&#39;iframe name&#39;) # 상위 iframe으로 이동 driver.switch_to.parent_frame() # 초기 frame으로 이동 driver.switch_to.default_content() . Screenshot . # 해당 엘리멘트 스크린샷 후 저장 element.screenshot(&quot;gd.png&quot;) # 특정 태그가 차지하는 만큼 스크린 샷 # body로 지정시 전체 스크린 샷 element = driver.find_elements(By.TAG_NAME, &quot;body&quot;) element.screenshot(&quot;test.png&quot;) . URL . # 현재 url 가져오기 driver.current_url . Title . # 웹페이지 타이틀 가져오기 driver.title . Clear text . # input 텍스트 초기화 element.clear() . Javascript . # user agent 가져오기 driver.execute_script(&#39;return navigator.userAgent&#39;) driver.execute_script(&quot;window.scrollTo(0,Y)&quot;) # Y까지 스크롤 내리기 driver.execute_script(&quot;window.scrollTo(0, document.body.scrollHeight)&quot;) # 끝까지 스크롤 . Find_element . ID, CSS_SELECTOR . elem = driver.find_element(By.ID,&quot;navbarMediumish&quot;) elems = driver.find_elements(By.CSS_SELECTOR, &quot;div.card-body &gt; h4&quot;) . Get_attribute . # 특정 attribute elem = driver.find_elements(By.TAG_NAME, &quot;meta&quot;) for item in elem: data = item.get_attribute(&#39;content&#39;) print(data) . Image . # 이미지 URL 추출 elems = driver.find_elements(By.CSS_SELECTOR, &quot;div.wrapthumbnail img&quot;) sources = list() for elem in elems: sources.append(elem.get_attribute(&#39;src&#39;)) . # 이미지 다운 받기 from urllib.request import urlretrieve image_path = r&quot;C: Users tgkang Documents 크롤링2 103 &quot; for index, source in enumerate(sources): urlretrieve(source, image_path + &quot;image&quot; + str(index) + &quot;.&quot; + source.split(&quot;.&quot;)[-1]) . Xpath . / : 절대경로를 나타냄 (예: /html/body/div/div) | // : 문서내에서 검색 (예: //h1 -&gt; h1 태그를 가진 데이터를 선택) | //*[@href] : href 속성이 있는 모든 태그 선택 | //a[@href=&#39;http://google.com&#39;] : a 태그의 href 속성에 http://google.com 속성값을 가진 모든 태그 선택 | (//a)[3] : 문서의 세 번째 링크 선택 | (//table)[last()] : 문서의 마지막 테이블 선택 | (//a)[position() &lt; 3] : 문서의 처음 두 링크 선택 | //div[@*] 속성이 하나라도 있는 div 태그 선택 | . # h1 태그 중 첫번째 태그 가져오기 title = driver.find_element(By.XPATH, &quot;//h1&quot;) # href 속성 모두 선택 datas = driver.find_elements(By.XPATH, &#39;//*[@href]&#39;) # ID = begin 인 속성 모두 찾기 datas = driver.find_elements(By.XPATH, &#39;//*[@id=&quot;begin&quot;]&#39;) # class 의 값이 skill-name 인 div 태그들 중에, HTML 코드 위에서 세번째 해당하는 div 태그 선택 datas = driver.find_elements(By.XPATH, &quot;//div[@class=&#39;skill-name&#39;]&quot;) # class값이 best-list 이고 그 아래 ul li a 태그 datas = driver.find_elements(By.XPATH, &quot;//div[@class=&#39;best-list&#39;]/ul/li/a&quot;) # 첫 번째 데이터 선택 item = driver.find_element(By.XPATH, &quot;(//tr)[position()=1]&quot;) # 3 번째 보다 작은 번째 선택 item = driver.find_element(By.XPATH, &quot;(//tr)[position()&lt;3]&quot;) # 마지막 데이터 선택 item = driver.find_element(By.XPATH, &quot;(//tr)[last()]&quot;) # 속성을 하나 이상 가진 p 태그 item = driver.find_element_by_xpath(&quot;//p[@*]&quot;) # 다중 선택 elem = driver.find_element_by_xpath(&quot;//*[contains(@class, &#39;course&#39;) and contains(@class, &#39;paid&#39;)]&quot;) . Title tag &#50696;&#50808; . # css selector로 title을 선택해서 text를 뽑으면 나오지 않음 elem = driver.find_element(By.CSS_SELECTOR, &quot;title&quot;) print (&#39;text:&#39;, elem.text) # 가져오지 않음(# text는 보통 body안의 내용을 뽑을 때만) print (&#39;get_attribute:&#39;, elem.get_attribute(&#39;text&#39;)) # 가져와짐 print (&#39;driver.title:&#39;, driver.title) # elem = driver.find_element_by_css_selector(&#39;h1&#39;) elem = driver.find_element(By.CSS_SELECTOR, &quot;h1&quot;) print (&#39;text:&#39;, elem.text) # 됨 print (&#39;get_attribute:&#39;, elem.get_attribute(&#39;text&#39;)) # 될 것 처럼 보이지만 안된다. . Send_key . from selenium.webdriver.common.keys import Keys # 사용가능한 키 조회 dir(Keys) # 키 이벤트 전송 elem.send_keys(&quot;error@error.com&quot;) # 엔터 입력 elem.send_keys(Keys.RETURN) . Scrapy . &#49444;&#52824; . # 윈도우/맥 공통 ! pip install scrapy . # 윈도우에서 정상 설치 안될 시 ! pip install --upgrade setuptools ! pip install pypiwin32 ! pip install twisted[tls] . &#54532;&#47196;&#51229;&#53944; &#49373;&#49457; . # 프로젝트 생성 scrapy startproject ecommerce # 크롤러 작성 scrapy genspider &lt;크롤러이름&gt; &lt;크롤링주소&gt; scrapy genspider gmarket &quot;www.gmarket.co.kr&quot; # 크롤러 실행 scrapy crawl gmarket . Scrapy shell . # Scrapy shell 접속 scrapy shell &quot;http://corners.gmarket.co.kr/Bestsellers&quot; exit # 종료 # response요청한 페이지 보기 view(response) # response url 확인 response.url . element . # css selector response.css(&#39;head &gt; title&#39;).get() response.css(&#39;head &gt; title&#39;).getall() response.css(&#39;head &gt; title::text&#39;).get() response.css(&#39;div.best-list li &gt; a::text&#39;).getall() response.css(&#39;div.best-list li &gt; a::text&#39;)[1].get() . # xpath response.xpath(&#39;//div[@class=&quot;best-list&quot;]/ul/li/a&#39;).getall() response.xpath(&#39;//div[@class=&quot;best-list&quot;]/ul/li/a/text()&#39;).getall() . # re 정규표신혁 # n은 파이썬 3.0 이상은 한글도 포함 but reg 홈페이지에는 반영 안되어 있음 response.css(&#39;div.best-list li &gt; a::text&#39;)[1].re(&#39;( w+)&#39;) response.xpath(&#39;//div[@class=&quot;best-list&quot;]/ul/li/a/text()&#39;)[1].re(&#39;( w+)&#39;) . Excel . import win32com.client as win32 excel = win32.gencache.EnsureDispatch(&#39;Excel.Application&#39;) wb = excel.Workbooks.Add() ws = wb.Sheets(&quot;Sheet1&quot;) rng = ws.Range(&quot;B2&quot;) image = ws.Shapes.AddPicture(r&quot;C: Users tgkang Documents 크롤링2 103 image0.jpg&quot;, False, True, rng.Left, rng.Top, 100, 100) excel.Visible=True . openpyxl . &#54056;&#53556; . # 엑셀 파일 읽기 import openpyxl excel_file = openpyxl.load_workbook(&#39;tmp.xlsx&#39;) excel_sheet = excel_file.active # excel_sheet = excel_file.get_sheet_by_name(&#39;IT뉴스&#39;) # 데이터 읽기 for row in excel_sheet.rows: print(row[0].value, row[1].value) excel_file.close() . Syntax . # 파일 가져오기 excel_file = openpyxl.load_workbook(r&#39;C: Users tgkang Documents 크롤링1 tmp.xlsx&#39;) # 파일 생성 excel_file = openpyxl.Workbook() # 활성화 excel_sheet = excel_file.active # 시트 이름 excel_sheet.title = &#39;testsheet&#39; # 시트 선택 excel_sheet = excel_file[&quot;상품정보&quot;] # sheet name 확인하기 excel_file.sheetnames # 컬럼 크기 변경 excel_sheet.column_dimensions[&#39;A&#39;].width = 100 excel_sheet.column_dimensions[&#39;B&#39;].width = 20 # 데이터 입력 excel_sheet.append([&quot;하이&quot;]) # 파일 저장 excel_file.save(&quot;피카피카.xlsx&quot;) # 파일 닫기 excel_file.close() . &#51060;&#48120;&#51648; . import win32com.client as win32 excel = win32.gencache.EnsureDispatch(&#39;Excel.Application&#39;) wb = excel.Workbooks.Add() ws = wb.Sheets(&quot;Sheet1&quot;) rng = ws.Range(&quot;B2&quot;) image = ws.Shapes.AddPicture(r&quot;C: Users tgkang Documents 크롤링2 103 image0.jpg&quot;, False, True, rng.Left, rng.Top, 100, 100) excel.Visible=True . openAPI . naver . &#44592;&#48376; &#54056;&#53556; . import requests import pprint client_id = &#39;BTMVavws8Is7jmVpUcSL&#39; client_secret = &#39;sDgiapg86l&#39; naver_open_api = &#39;https://openapi.naver.com/v1/search/shop.json?query=갤럭시노트10&#39; header_params = {&quot;X-Naver-Client-Id&quot;:client_id, &quot;X-Naver-Client-Secret&quot;:client_secret} res = requests.get(naver_open_api, headers=header_params) # header에 아이디 넣어보냄 if res.status_code == 200: data = res.json() for index, item in enumerate(data[&#39;items&#39;]): print (index + 1, item[&#39;title&#39;], item[&#39;link&#39;]) else: print (&quot;Error Code:&quot;, res.status_code) . &#50641;&#49472; &#51200;&#51109; . import requests import openpyxl client_id = &#39;CgZgjTdS7F2naaLEhWRg&#39; client_secret = &#39;oCwEtEw08Y&#39; start, num = 1, 0 # 시작 페이지, 인덱스 설정 excel_file = openpyxl.Workbook() excel_sheet = excel_file.active excel_sheet.column_dimensions[&#39;B&#39;].width = 100 # 셀 너비 조정 excel_sheet.column_dimensions[&#39;C&#39;].width = 100 excel_sheet.append([&#39;랭킹&#39;, &#39;제목&#39;, &#39;링크&#39;]) for index in range(10): start_number = start + (index * 100) naver_open_api = &#39;https://openapi.naver.com/v1/search/shop.json?query=샤오미&amp;display=100&amp;start=&#39; + str(start_number) header_params = {&quot;X-Naver-Client-Id&quot;:client_id, &quot;X-Naver-Client-Secret&quot;:client_secret} res = requests.get(naver_open_api, headers=header_params) if res.status_code == 200: data = res.json() for item in data[&#39;items&#39;]: num += 1 excel_sheet.append([num, item[&#39;title&#39;], item[&#39;link&#39;]]) else: print (&quot;Error Code:&quot;, res.status_code) excel_file.save(&#39;IT.xlsx&#39;) excel_file.close() . &#51221;&#44508;&#54868; . &#47928;&#51088;&#50676; &#52376;&#47532; . string = &quot;12345&quot; comma = &#39;,&#39; comma.join(string) . &#39;1,2,3,4,5&#39; . string = &quot; 9999999999999999(Dave)888888888888888888 &quot; string.strip(&quot; 98()&quot;) # 앞 뒤 괄호를 다 지움 . &#39;Dave&#39; . string = &quot;Dave goes to Korea&quot; string.split()[3] . &#39;Korea&#39; . &#51221;&#44508;&#49885; . 정규 표현식 축약 표현 사용 예 . [0-9] | d | 숫자를 찾음 | . [^0-9] | D | 숫자가 아닌 것을 찾음(텍스트, 특수 문자, white space(스페이스, 탭, 엔터 등등)를 찾을 때) | . [ t n r f v] | s | white space(스페이스, 탭, 엔터 등등) 문자인 것을 찾음 | . [^ t n r f v] | S | white space(스페이스, 탭, 엔터 등등) 문자가 아닌 것을 찾음(텍스트, 특수 문자, 숫자를 찾을 때) | . [A-Za-z0-9] | w | 문자, 숫자를 찾음 | . [^A-Za-z0-9] | W | 문자, 숫자가 아닌 것을 찾음 | . sub . string = &#39;(초급) - 강사가 실제 사용하는 자동 프로그램 소개 [2]&#39; import re print(re.sub(&#39; [[0-9]+ ]&#39;, &#39;&#39;, string)) print(re.sub(&#39;프로그램&#39;, &#39;모듈&#39;, string)) # 찾아 바꾸기 . (초급) - 강사가 실제 사용하는 자동 프로그램 소개 (초급) - 강사가 실제 사용하는 자동 모듈 소개 [2] . import re pattern2 = re.compile(&#39;-&#39;) subed = pattern2.sub(&#39;*&#39;, &#39;801210-1011323&#39;) # sub(바꿀문자열, 본래문자열) subed . &#39;801210*1011323&#39; . pattern . pattern = re.compile(&#39;D.A&#39;) # .은 모든 숫자 및 문자 print(pattern.search(&quot;DAA&quot;)) # 해당 print(pattern.search(&quot;D1A&quot;)) # 해당 print(pattern.search(&quot;D00A&quot;)) # 해당 x print(pattern.search(&quot;d0A&quot;)) # 해당 x print(pattern.search(&quot;d0A D1A 0111&quot;)) # 해당 . &lt;re.Match object; span=(0, 3), match=&#39;DAA&#39;&gt; &lt;re.Match object; span=(0, 3), match=&#39;D1A&#39;&gt; None None &lt;re.Match object; span=(4, 7), match=&#39;D1A&#39;&gt; . pattern = re.compile(&#39;D .A&#39;) # 정말 기호 적용 print(pattern.search(&quot;D.A&quot;)) # 해당 print(pattern.search(&quot;DDA&quot;)) # 해당 x . &lt;re.Match object; span=(0, 3), match=&#39;D.A&#39;&gt; None . pattern = re.compile(&#39;D[.]A&#39;) # 정말 기호 적용 print(pattern.search(&quot;D.A&quot;)) # 해당 print(pattern.search(&quot;DDA&quot;)) # 해당 x . &lt;re.Match object; span=(0, 3), match=&#39;D.A&#39;&gt; None . match &#50752; search &#54632;&#49688; . match : 문자열 처음부터 정규식과 매칭되는 패턴을 찾아서 리턴 | search : 문자열 전체를 검색해서 정규식과 매칭되는 패턴을 찾아서 리턴 | . import re pattern = re.compile(&#39;[a-z]+&#39;) matched = pattern.match(&#39;Dave&#39;) print(matched) searched = pattern.search(&quot;Dave&quot;) print(searched) . None &lt;re.Match object; span=(1, 4), match=&#39;ave&#39;&gt; . findall . 정규표현식과 매칭되는 모든 문자열을 리스트 객체로 리턴함 . import re pattern = re.compile(&#39;[a-z]+&#39;) findalled = pattern.findall(&#39;Game of Life in Python&#39;) print (findalled) . [&#39;ame&#39;, &#39;of&#39;, &#39;ife&#39;, &#39;in&#39;, &#39;ython&#39;] . import re pattern = re.compile(&#39;[a-z]+&#39;) findalled = pattern.findall(&#39;GAME&#39;) if len(findalled) &gt; 0: print (&quot;정규표현식에 맞는 문자열이 존재함&quot;) else: print (&quot;정규표현식에 맞는 문자열이 존재하지 않음&quot;) . 정규표현식에 맞는 문자열이 존재하지 않음 . split . import re pattern2 = re.compile(&#39;:&#39;) splited = pattern2.split(&#39;python:java&#39;) splited . [&#39;python&#39;, &#39;java&#39;] . ? , * , + . ? 는 앞 문자가 0번 또는 1번 표시되는 패턴 (없어도 되고, 한번 있어도 되는 패턴) | * 는 앞 문자가 0번 또는 그 이상 반복되는 패턴 | + 는 앞 문자가 1번 또는 그 이상 반복되는 패턴 | . pattern = re.compile(&#39;D?A&#39;) print(pattern.search(&quot;A&quot;)) print(pattern.search(&quot;DA&quot;)) print(pattern.search(&quot;DDDDDDA&quot;)) . &lt;re.Match object; span=(0, 1), match=&#39;A&#39;&gt; &lt;re.Match object; span=(0, 2), match=&#39;DA&#39;&gt; &lt;re.Match object; span=(5, 7), match=&#39;DA&#39;&gt; . pattern = re.compile(&#39;D*A&#39;) print(pattern.search(&quot;DA&quot;)) print(pattern.search(&quot;DDDDDDDDDDDDDDDDDDDDDDDDDDDDA&quot;)) . &lt;re.Match object; span=(0, 1), match=&#39;A&#39;&gt; &lt;re.Match object; span=(0, 2), match=&#39;DA&#39;&gt; &lt;re.Match object; span=(0, 29), match=&#39;DDDDDDDDDDDDDDDDDDDDDDDDDDDDA&#39;&gt; . {n}, {m,n} . {n} : 앞 문자가 n 번 반복되는 패턴 | {m, n} : 앞 문자가 m 번 반복되는 패턴부터 n 번 반복되는 패턴까지 | . pattern = re.compile(&#39;AD{2}A&#39;) print(pattern.search(&quot;ADA&quot;)) print(pattern.search(&quot;ADDA&quot;)) print(pattern.search(&quot;ADDDA&quot;)) . None &lt;re.Match object; span=(0, 4), match=&#39;ADDA&#39;&gt; None . pattern = re.compile(&#39;AD{2,6}A&#39;) # {m,n} 은 붙여 써야 함 {m, n} 으로 쓰면 안됨(특이함) print(pattern.search(&quot;ADDA&quot;)) print(pattern.search(&quot;ADDDA&quot;)) print(pattern.search(&quot;ADDDDDDA&quot;)) . &lt;re.Match object; span=(0, 4), match=&#39;ADDA&#39;&gt; &lt;re.Match object; span=(0, 5), match=&#39;ADDDA&#39;&gt; &lt;re.Match object; span=(0, 8), match=&#39;ADDDDDDA&#39;&gt; . [ ] &#44292;&#54840; &#45236; &#47928;&#51088; . 예: [abc] 는 a, b, c 중 하나가 들어 있는 패턴을 말함 | . pattern = re.compile(&#39;[abcdefgABCDEFG]&#39;) print(pattern.search(&quot;a1234&quot;)) print(pattern.search(&quot;z1234&quot;) ) . &lt;re.Match object; span=(0, 1), match=&#39;a&#39;&gt; None . [a-zA-Z0-9] . pattern = re.compile(&#39;[a-zA-Z0-9]&#39;) print(pattern.search(&quot;1234&quot;) ) print(pattern.search(&quot;!@#!@$!$%#%%%#%%@$!$!&quot;) ) . [^] . pattern = re.compile(&#39;[^a-zA-Z0-9]&#39;) pattern.search(&quot;!@#!@$!$%#%%%#%%@$!$!&quot;) . &lt;re.Match object; span=(0, 1), match=&#39;-&#39;&gt; . pattern = re.compile(&#39;[^ t n r f v]&#39;) pattern.search(&quot;-&quot;) . &#44032;-&#55203; . pattern = re.compile(&#39;[가-힣]&#39;) pattern.search(&quot;안&quot;) . &lt;re.Match object; span=(0, 1), match=&#39;안&#39;&gt; . &#54876;&#50857;&#50696;&#51228; . import openpyxl work_book = openpyxl.load_workbook(r&#39;C: Users tgkang Documents 크롤링1 data_kr.xlsx&#39;) work_sheet = work_book.active for each_row in work_sheet.rows: print(re.sub(&#39;-[0-9]{7}&#39;, &#39;-*******&#39;, each_row[1].value)) work_book.close() . 주민등록번호 800215-******* 821030-******* 841230-******* 790903-******* 800125-******* 820612-******* . import requests from bs4 import BeautifulSoup .",
            "url": "https://tg0708.github.io/testcolabblog/manual/2022/07/05/_07-05-code2.html",
            "relUrl": "/manual/2022/07/05/_07-05-code2.html",
            "date": " • Jul 5, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "마크다운 테스트",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://tg0708.github.io/testcolabblog/deep%20learning/markdown/2022/07/04/%EB%A7%88%ED%81%AC%EB%8B%A4%EC%9A%B4_%ED%85%8C%EC%8A%A4%ED%8A%B8.html",
            "relUrl": "/deep%20learning/markdown/2022/07/04/%EB%A7%88%ED%81%AC%EB%8B%A4%EC%9A%B4_%ED%85%8C%EC%8A%A4%ED%8A%B8.html",
            "date": " • Jul 4, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://tg0708.github.io/testcolabblog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://tg0708.github.io/testcolabblog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://tg0708.github.io/testcolabblog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://tg0708.github.io/testcolabblog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}